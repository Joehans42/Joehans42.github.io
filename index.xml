<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Project B</title>
    <link>https://joehans42.github.io/</link>
    <description>Recent content on Project B</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Dec 2021 00:13:45 +0100</lastBuildDate><atom:link href="https://joehans42.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>The Data</title>
      <link>https://joehans42.github.io/post/data/</link>
      <pubDate>Tue, 07 Dec 2021 20:09:52 +0100</pubDate>
      
      <guid>https://joehans42.github.io/post/data/</guid>
      <description>Introduction The data in this project consists of two separate data sets. The first data set is a list of Wikipedia articles. The Wikipedia articles can be different depending on the choosing of an initial starting page. In this data set however, the initial starting page is pre-selected as the Wikipedia page for Albert Einstein. The first data set is thus a network consisting of the articles that can be reached by clicking the links on the pages within 2 clicks.</description>
    </item>
    
    <item>
      <title>Analysis</title>
      <link>https://joehans42.github.io/post/analysis/</link>
      <pubDate>Mon, 06 Dec 2021 23:57:44 +0100</pubDate>
      
      <guid>https://joehans42.github.io/post/analysis/</guid>
      <description>Introduction We have the data, so we should begin by learning a bit about the properties of the networks extracted from the data. The things we are interested in are things like the average degree of a node, the size of the giant components in the data, weak and strong. We also want to know something about the connectivity of the nodes. Which nodes have the highest in- and out-degree? What does the node distribution look like?</description>
    </item>
    
    <item>
      <title>Interactive Visualisation</title>
      <link>https://joehans42.github.io/post/visualisation/</link>
      <pubDate>Sun, 05 Dec 2021 20:09:52 +0100</pubDate>
      
      <guid>https://joehans42.github.io/post/visualisation/</guid>
      <description>Pyvis To visualise the data, I have used the Python framework, Pyvis. It is an interactive visualisation that allows for zooming in on individual nodes and their edges. What you see on the graph below here is a sample of the entire SNAP data set. Since Python has a hard time plotting and visualising 4604 nodes with 119882 edges, I have simply sampled 2000 edges from the network and plotted them with Pyvis.</description>
    </item>
    
    <item>
      <title>Explainer Notebook</title>
      <link>https://joehans42.github.io/post/notebook/</link>
      <pubDate>Sat, 04 Dec 2021 18:40:59 +0100</pubDate>
      
      <guid>https://joehans42.github.io/post/notebook/</guid>
      <description>Project B Link to the website: https://joehans42.github.io/
Motivation   The data   The first data set that I am using for this project consists of the list of wikipedia articles, which can be reached in 2 clicks from the Albert Einstein Wikipedia page. This data set has 65233 articles (nodes) with 98707 links between each other (edges). The second data set is a data set from the Stanford Network Analysis Project (SNAP).</description>
    </item>
    
  </channel>
</rss>
